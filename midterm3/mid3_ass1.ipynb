{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6d7a53e",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "spiega l'architettura del conv e del dense\n",
    "\n",
    "spiega il training loop coi vari parametri usati (non scordare add_noise)\n",
    "\n",
    "spiega come funziona evaluate, ovvero che metriche stai usando e perch√©\n",
    "\n",
    "spiega la funzione per visualizzare le immagini\n",
    "\n",
    "blocchi dove alleni e valuti (scegliere se trattare contemporanemente i dae o meno)\n",
    "\n",
    "conclusioni"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc2ead",
   "metadata": {},
   "source": [
    "# Midterm 3, Assignment 1 - Gaetano Barresi [579102]\n",
    "\n",
    "A Denoising Autoencoder (DAE) is a neural network that learns robust latent representations by reconstructing clean inputs from corrupted data. Unlike standard autoencoders that simply reconstruct the original inputs, a DAE must remove noise from artificially corrupted inputs and discover stable features that capture the true data distribution. The goal of this work is to train two versions of a DAE on the CIFAR10 dataset, one using dense layers and one using convolutional layers and to show an accuracy comparison between them.\n",
    "\n",
    "The architecture of a DAE has the following form:\n",
    "\n",
    "$$\n",
    "\\\n",
    "[Input] ‚Üí [Corruption] ‚Üí [Encoder] ‚Üí [Latent Code] ‚Üí [Decoder] ‚Üí [Reconstruction]\n",
    "\\\n",
    "$$\n",
    "\n",
    "$[Input]$ is self-explanatory. $[Corruption]$ is the stage where we inject artificial noise to the input through some noise process $C(\\hat{x} ‚à£ x)$ and obtain $\\hat{x}$, a corrupted version of the original input. In this work the corruption process is done via standard Gaussian noise, so:\n",
    "\n",
    "$$\n",
    "\\\n",
    "\\hat{x} = x + œµ, œµ ‚àº ùí©(0, œÉ^2).\n",
    "\\\n",
    "$$\n",
    "\n",
    "$[Encoder]$ $f()$ maps noisy input $\\hat{x}$ to latent representation $z$:\n",
    "\n",
    "$$\n",
    "\\\n",
    "z = f(\\hat{x}) ‚àà ‚Ñù·µà,\n",
    "\\\n",
    "$$\n",
    "\n",
    "where $d << input\\_dim$. Learned $[Latent Code]$ $z$ should be robust to partial destruction of the input.\n",
    "$[Decoder]$ $g()$ reconstructs clean input from $z$:\n",
    "\n",
    "$$\n",
    "\\\n",
    "x' = g(z) ‚âà x,\n",
    "\\\n",
    "$$\n",
    "\n",
    "where $x'$ is our $[Reconstruction]$.\n",
    "\n",
    "The \"magic\" of DAEs lies in their bottleneck architecture. As data passes through the encoder, the network gradually compresses the input while stripping away noise and preserving only the most essential features. This forced dimensionality reduction creates a distilled latent representation containing only the core patterns needed for reconstruction. The decoder then reverses this process, carefully rebuilding the clean input from these compressed features layer by layer. By training on noisy-clean pairs, the network learns to discard random corruptions during compression while maintaining the structural integrity needed for accurate reconstruction.\n",
    "\n",
    "More formally, the DAE is trained to minimize the loss function\n",
    "\n",
    "$$\n",
    "\\\n",
    "L = (x, g(f(\\hat{x}))),\n",
    "\\\n",
    "$$\n",
    "\n",
    "or, using a probabilistic interpretation, the DAE learns the denoising distribuition\n",
    "\n",
    "$$\n",
    "\\\n",
    "P(x|\\hat{x})\n",
    "\\\n",
    "$$\n",
    "\n",
    "by minimizing\n",
    "\n",
    "$$\n",
    "\\\n",
    "-log P(x|z = f(\\hat{x})).\n",
    "\\\n",
    "$$\n",
    "\n",
    "After this brief introduction, we proceed with the implementation. First, we need to load and preprocess the dataset. We normalize the CIFAR-10 data to the range [-1, 1] to achieve several benefits such as: compatibility with the tanh activation, effective noise handling due to the symmetric range that ensures Gaussian noise is equally well-handled in both positive and negative directions, gradient flow optimization, numerical stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac25293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# transform for CIFAR-10, normalizing to [-1, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Range: [-1, 1]\n",
    "])\n",
    "# Load TR set\n",
    "train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "# Load TS set\n",
    "test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_data, batch_size=100, shuffle=False)\n",
    "\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084f0f1b",
   "metadata": {},
   "source": [
    "To implement the DAE, we subclass PyTorch‚Äôs `nn.Module` base class, inheriting its core functionality for neural network operations. With a single class we can specify which kind of DAE to instantiate, a dense or a convolutional one. \n",
    "\n",
    "\n",
    "\n",
    "The `forward()` method will slightly change behaviour according to the DAE selected.\n",
    "\n",
    "The class has methods to train and evaluate the DAE:\n",
    "- `train_model()` is a classical training loop. We use MSE loss, Adam optimizer and a learnig rate of 1e-4\n",
    "- `evaluate()`\n",
    "- `visualize_result()`\n",
    "\n",
    "We have a function `add_noise()` used inside the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebefd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class DAE(nn.Module):\n",
    "    def __init__(self, mode=None):\n",
    "        super(DAE, self).__init__()\n",
    "\n",
    "        self.mode = mode\n",
    "\n",
    "        if mode == 'conv':\n",
    "            # Convolutional Encoder\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Conv2d(3, 64, 3, padding=1),   # 32x32\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(64, 128, 3, padding=1), # 16x16\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(128, 256, 3, padding=1) # 8x8\n",
    "            )\n",
    "            # Convolutional Decoder\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.Conv2d(256, 128, 3, padding=1),  # 8x8\n",
    "                nn.ReLU(),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(128, 64, 3, padding=1),   # 16x16\n",
    "                nn.ReLU(),\n",
    "                nn.Upsample(scale_factor=2),\n",
    "                nn.Conv2d(64, 3, 3, padding=1),     # 32x32\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        elif mode == 'dense':\n",
    "            # Dense Encoder\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Linear(3 * 32 * 32, 1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(1024, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 256),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            # Dense Decoder\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.Linear(256, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(512, 1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(1024, 3 * 32 * 32),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode. Choose 'conv' or 'dense'.\")\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.mode == 'conv':\n",
    "            x = self.encoder(x)\n",
    "            x = self.decoder(x)\n",
    "        else:\n",
    "            x = x.view(x.size(0), -1)  # Flatten to (batch_size, 3072)\n",
    "            x = self.encoder(x)\n",
    "            x = self.decoder(x)\n",
    "            x = x.view(-1, 3, 32, 32)  # Reshape to image dimensions\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def add_noise(self, inputs, noise_factor=0.2):\n",
    "        noise = noise_factor * torch.randn_like(inputs)\n",
    "        noisy = inputs + noise\n",
    "        return torch.clamp(noisy, -1., 1.)  # CIFAR-10 is normalized to [-1, 1]\n",
    "\n",
    "\n",
    "    def train_model(self, train_loader, num_epochs=20, lr=1e-4, print_interval=100):\n",
    "        #parameter print_interval (int): Print loss every N examples\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "        \n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        \n",
    "        self.train()  # Set to training mode\n",
    "        for epoch in range(num_epochs):\n",
    "            for batch_idx, (clean_imgs, _) in enumerate(train_loader):\n",
    "                clean_imgs = clean_imgs.to(device)\n",
    "                \n",
    "                # Add noise and reconstruct\n",
    "                noisy_imgs = self.add_noise(clean_imgs)\n",
    "                reconstructed = self(noisy_imgs)\n",
    "                \n",
    "                # Compute loss and update\n",
    "                loss = self.criterion(reconstructed, clean_imgs)\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # Print progress\n",
    "                if batch_idx % print_interval == 0:\n",
    "                    print(f\"Epoch [{epoch+1}/{num_epochs}], Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "    def evaluate(self, test_loader, noise_factor=0.2):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "\n",
    "        #Compute PSNR and SSIM on test set\n",
    "        self.eval()  # Set to evaluation mode\n",
    "        total_psnr = 0.0\n",
    "        total_ssim = 0.0\n",
    "        num_samples = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for clean_imgs, _ in test_loader:\n",
    "                clean_imgs = clean_imgs.to(device)\n",
    "                noisy_imgs = self.add_noise(clean_imgs, noise_factor)\n",
    "                reconstructed = self(noisy_imgs)\n",
    "                \n",
    "                # Convert to numpy (CPU) for metric calculation\n",
    "                clean_np = clean_imgs.cpu().numpy()\n",
    "                recon_np = reconstructed.cpu().numpy()\n",
    "                \n",
    "                # Compute metrics per image\n",
    "                for i in range(clean_np.shape[0]):\n",
    "                    # PSNR (higher is better)\n",
    "                    total_psnr += psnr(clean_np[i], recon_np[i], data_range=2.0)  # data_range=2 for [-1,1]\n",
    "                    \n",
    "                    # SSIM (higher is better, multichannel=True for RGB)\n",
    "                    total_ssim += ssim(clean_np[i].transpose(1,2,0), \n",
    "                                     recon_np[i].transpose(1,2,0), \n",
    "                                     data_range=2.0, \n",
    "                                     channel_axis=2)\n",
    "                \n",
    "                num_samples += clean_np.shape[0]\n",
    "        \n",
    "        avg_psnr = total_psnr / num_samples\n",
    "        avg_ssim = total_ssim / num_samples\n",
    "        return avg_psnr, avg_ssim\n",
    "    \n",
    "\n",
    "    def visualize_results(self, test_loader, num_images=5):\n",
    "        #Plot noisy vs reconstructed vs clean images\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(device)\n",
    "\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            clean_imgs, _ = next(iter(test_loader))\n",
    "            clean_imgs = clean_imgs.to(device)[:num_images]\n",
    "            noisy_imgs = self.add_noise(clean_imgs)\n",
    "            reconstructed = self(noisy_imgs)\n",
    "            \n",
    "            # Denormalize to [0,1] for plotting\n",
    "            clean_imgs = (clean_imgs + 1) / 2\n",
    "            noisy_imgs = (noisy_imgs + 1) / 2\n",
    "            reconstructed = (reconstructed + 1) / 2\n",
    "            \n",
    "            fig, axes = plt.subplots(num_images, 3, figsize=(10, num_images*2))\n",
    "            for i in range(num_images):\n",
    "                axes[i,0].imshow(noisy_imgs[i].cpu().permute(1,2,0))\n",
    "                axes[i,0].set_title(\"Noisy\")\n",
    "                axes[i,1].imshow(reconstructed[i].cpu().permute(1,2,0))\n",
    "                axes[i,1].set_title(\"Reconstructed\")\n",
    "                axes[i,2].imshow(clean_imgs[i].cpu().permute(1,2,0))\n",
    "                axes[i,2].set_title(\"Clean\")\n",
    "                for ax in axes[i]:\n",
    "                    ax.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mid3_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
