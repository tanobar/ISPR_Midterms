{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6d7a53e",
   "metadata": {},
   "source": [
    "NOTES\n",
    "\n",
    "SSIM loss(?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc2ead",
   "metadata": {},
   "source": [
    "# Midterm 3, Assignment 1 - Gaetano Barresi [579102]\n",
    "\n",
    "A Denoising Autoencoder (DAE) is a neural network that learns robust latent representations by reconstructing clean inputs from corrupted data. Unlike standard autoencoders that simply reconstruct the original inputs, a DAE must remove noise from artificially corrupted inputs and discover stable features that capture the true data distribution, so, learned representations should be robust to partial destruction of the input. The goal of this work is to train two versions of a DAE on the CIFAR10 dataset, one using dense layers and one using convolutional layers and to show an accuracy comparison between them.\n",
    "\n",
    "The architecture of a DAE has the following form:\n",
    "\n",
    "$$\n",
    "\\\n",
    "[Input] ‚Üí [Corruption] ‚Üí [Encoder] ‚Üí [Latent Code] ‚Üí [Decoder] ‚Üí [Reconstruction]\n",
    "\\\n",
    "$$\n",
    "\n",
    "$[Input]$ is self-explanatory. $[Corruption]$ is the stage where we inject artificial noise to the input through some noise process $C(\\hat{x} ‚à£ x)$ and obtain $\\hat{x}$, a corrupted version of the original input. In this work the corruption process is done via standard Gaussian noise, so:\n",
    "\n",
    "$$\n",
    "\\\n",
    "\\hat{x} = x + œµ, œµ ‚àº ùí©(0, œÉ^2)\n",
    "\\\n",
    "$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mid3_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
